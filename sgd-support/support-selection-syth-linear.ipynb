{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.nn import ReLU\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from typing import Optional\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_init = 0\n",
    "hiddens = [15, 15, 15]\n",
    "n_iters_gd = 20_000\n",
    "n_iters_sgd = 200_000\n",
    "n_iters_gdwd = 5_000\n",
    "n_trajs = 4\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seedall(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000 # number of samples.\n",
    "d = 15 # dimension of the data.\n",
    "r = 5 # end-index of relevant features.\n",
    "\n",
    "seedall(seed_init)\n",
    "\n",
    "# Sample raw data at first.\n",
    "x = np.random.randn(n, d)\n",
    "\n",
    "# Prepare the data as per assumptions.\n",
    "idx_to_center = range(r, d)\n",
    "means = np.mean(x[:, idx_to_center], axis=0)\n",
    "x[:, idx_to_center] -= means\n",
    "\n",
    "# Define generating function.\n",
    "W = np.array([1] * d) # np.random.randn(d)\n",
    "W[r:] = 0 # Set to zero irrelevant features.\n",
    "\n",
    "# Gaussian noise.\n",
    "eps = 0.001 * np.random.randn(n)\n",
    "\n",
    "# Generate labels.\n",
    "y1 = ((x @ W) + eps).reshape(-1, 1) # Linear.\n",
    "y2 = ((x @ W) - eps).reshape(-1, 1) # Linear rev.\n",
    "\n",
    "x = np.concatenate([x, x], axis=0)\n",
    "y = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "# Map to PyTorch tensors.\n",
    "xt = torch.from_numpy(x).float()\n",
    "yt = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure that data features are not correlated.\n",
    "cov = xt.T @ xt\n",
    "plt.imshow(cov, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define our proper model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        act_func: Optional[nn.Module] = None,\n",
    "        skip_connections: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        modules = OrderedDict()\n",
    "        modules[\"linear\"] = nn.Linear(in_features=in_features, out_features=out_features, bias=bias)\n",
    "        modules[\"activation\"] = act_func if act_func is not None else nn.Identity()\n",
    "        self.linear_act_block = nn.Sequential(modules)\n",
    "        self.skip_connections = skip_connections\n",
    "        if skip_connections and in_features != out_features:\n",
    "            self.adjust_dim = nn.Linear(in_features, out_features, bias=False)\n",
    "        else:\n",
    "            self.adjust_dim = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.skip_connections:\n",
    "            x_adj = self.adjust_dim(x) if self.adjust_dim is not None else x\n",
    "            return x_adj + self.linear_act_block(x)\n",
    "        return self.linear_act_block(x)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        hidden_features: list[int],\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        act_func: Optional[nn.Module] = None,\n",
    "        skip_connections: bool = False,\n",
    "        init_method: str = \"he_normal\"\n",
    "    ) -> None:\n",
    "        super(MLP, self).__init__()\n",
    "        assert len(hidden_features) >= 1\n",
    "\n",
    "        modules = OrderedDict()\n",
    "        hidden_dims = [in_features] + hidden_features + [out_features]\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules[f\"layer_{i}\"] = LinearBlock(\n",
    "                in_features=hidden_dims[i],\n",
    "                out_features=hidden_dims[i + 1],\n",
    "                skip_connections=skip_connections,\n",
    "                # Use the activation function for all layers but last fc\n",
    "                act_func=act_func if i < len(hidden_dims) - 2 else None,\n",
    "                bias=bias,\n",
    "            )\n",
    "\n",
    "        self.layers = nn.Sequential(modules)\n",
    "        self.init_weights(self.layers, init_method)\n",
    "        self.penultimate = None\n",
    "        self.set_init()\n",
    "\n",
    "    def init_weights(self, module, init_method):\n",
    "        for child in module.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                self.apply_init(child, init_method)\n",
    "            else:\n",
    "                self.init_weights(child, init_method)\n",
    "\n",
    "    def apply_init(self, linear_layer, init_method):\n",
    "        if init_method == \"xavier_uniform\":\n",
    "            nn.init.xavier_uniform_(linear_layer.weight)\n",
    "        elif init_method == \"xavier_normal\":\n",
    "            nn.init.xavier_normal_(linear_layer.weight)\n",
    "        elif init_method == \"he_normal\":\n",
    "            nn.init.kaiming_normal_(linear_layer.weight, nonlinearity=\"relu\")\n",
    "        elif init_method == \"he_uniform\":\n",
    "            nn.init.kaiming_uniform_(linear_layer.weight, nonlinearity=\"relu\")\n",
    "\n",
    "    def embeddings(self, x):\n",
    "        activations = []\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x)\n",
    "            activations.append(x)\n",
    "        return activations\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.penultimate = self.layers[:-1](x)\n",
    "        logits = self.layers[-1](self.penultimate)\n",
    "        return logits\n",
    "    \n",
    "    def set_init(self):\n",
    "        self.W1_init = self.layers.layer_0.linear_act_block.linear.weight.detach().clone().numpy()\n",
    "        self.W2_init = self.layers.layer_1.linear_act_block.linear.weight.detach().clone().numpy()\n",
    "        self.W3_init = self.layers.layer_2.linear_act_block.linear.weight.detach().clone().numpy()\n",
    "        self.u_init, self.s_init, self.vh_init = np.linalg.svd(self.W1_init)\n",
    "        self.W1_init_svd = self.W1_init @ self.vh_init.T\n",
    "\n",
    "    def set_post(self):\n",
    "        self.W1_post = self.layers.layer_0.linear_act_block.linear.weight.detach().clone().numpy()\n",
    "        self.W2_post = self.layers.layer_1.linear_act_block.linear.weight.detach().clone().numpy()\n",
    "        self.W3_post = self.layers.layer_2.linear_act_block.linear.weight.detach().clone().numpy()\n",
    "        # self.u_post, self.s_post, self.vh_post = np.linalg.svd(self.W1_post)\n",
    "        # self.W1_post_svd = self.W1_post @ self.vh_post.T\n",
    "    \n",
    "    @staticmethod\n",
    "    def norm(model):\n",
    "        norm = 0\n",
    "        for param in model.parameters():\n",
    "            norm += param.data.norm(2) ** 2\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training loops utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, crit, opt, n_iters, seed_traj=0, clip_value=1.0):\n",
    "    # Set the seed.\n",
    "    seedall(seed_traj)\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(range(n_iters))\n",
    "    iters_idx, epoch_idx = 0, 0\n",
    "    losses, irelnorms = [], []\n",
    "\n",
    "    while iters_idx < n_iters:\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            if iters_idx >= n_iters: break\n",
    "\n",
    "            # forward pass.\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # backward pass.\n",
    "            opt.zero_grad()\n",
    "            loss = crit(outputs, targets)\n",
    "            loss.backward()\n",
    "            if clip_value > 0:\n",
    "                clip_grad_norm_(model.parameters(), clip_value)\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "            irelnorms.append(np.linalg.norm(model.layers.layer_0.linear_act_block.linear.weight.detach().numpy()[:,r:d]))\n",
    "\n",
    "            # move progress bar.\n",
    "            pbar.set_description(f\"epoch {epoch_idx+1} iter {iters_idx+1}/{n_iters} | train loss {loss.item():.3f} | norm {model.norm(model):.3f}\")\n",
    "            pbar.update(1)\n",
    "            iters_idx += 1\n",
    "\n",
    "        epoch_idx += 1\n",
    "\n",
    "    model.set_post()\n",
    "    model.irelnorms = irelnorms\n",
    "    model.losses = losses\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## magic functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(bs, lr, wd, hiddens, n_iters, with_relu=False, seed_traj=0):\n",
    "    # set the init seed.\n",
    "    seedall(seed_init)\n",
    "    \n",
    "    # create dataloader.\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(xt, yt),\n",
    "        batch_size=bs if bs > 0 else n*2, # set bs = -1 for GD.\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # set model\n",
    "    model = MLP(\n",
    "        in_features=d,\n",
    "        hidden_features=hiddens,\n",
    "        out_features=1,\n",
    "        act_func=ReLU() if with_relu else None,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "    # set optim and train.\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    crit = torch.nn.MSELoss()\n",
    "    train(model, dataloader, crit, opt, n_iters, seed_traj)\n",
    "\n",
    "    return model # model contains all infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13 iter 13/20000 | train loss 0.609 | norm 88.801:   0%|          | 12/20000 [00:00<16:01, 20.79it/s]"
     ]
    }
   ],
   "source": [
    "model_gd = experiment(-1, lr, 0.0, hiddens, n_iters=n_iters_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd512 = []\n",
    "for seed_traj in range(n_trajs):\n",
    "    print(f'seeding trajectory {seed_traj}')\n",
    "    model_sgd512.append(experiment(512, lr, 0.0, hiddens, n_iters=n_iters_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd128 = []\n",
    "for seed_traj in range(n_trajs):\n",
    "    print(f'seeding trajectory {seed_traj}')\n",
    "    model_sgd128.append(experiment(128, lr, 0.0, hiddens, n_iters=n_iters_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd32 = []\n",
    "for seed_traj in range(n_trajs):\n",
    "    print(f'seeding trajectory {seed_traj}')\n",
    "    model_sgd32.append(experiment(32, lr, 0.0, hiddens, n_iters=n_iters_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd01 = []\n",
    "for seed_traj in range(n_trajs):\n",
    "    print(f'seeding trajectory {seed_traj}')\n",
    "    model_sgd01.append(experiment(1, lr, 0.0, hiddens, n_iters=n_iters_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gdwd = experiment(-1, lr, 0.1, hiddens, n_iters=n_iters_gdwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gram matrices of first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_init = model_gd.W1_init\n",
    "W1_gd = model_gd.W1_post\n",
    "W1_sgd512 = model_sgd512[0].W1_post\n",
    "W1_sgd128 = model_sgd128[0].W1_post\n",
    "W1_sgd32 = model_sgd32[0].W1_post\n",
    "W1_sgd01 = model_sgd01[0].W1_post\n",
    "W1_gdwd = model_gdwd.W1_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_init = abs(W1_init.T @ W1_init)\n",
    "G1_gd = abs(W1_gd.T @ W1_gd)\n",
    "G1_sgd512 = abs(W1_sgd512.T @ W1_sgd512)\n",
    "G1_sgd128 = abs(W1_sgd128.T @ W1_sgd128)\n",
    "G1_sgd32 = abs(W1_sgd32.T @ W1_sgd32)\n",
    "G1_sgd01 = abs(W1_sgd01.T @ W1_sgd01)\n",
    "G1_gdwd = abs(W1_gdwd.T @ W1_gdwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = [G1_init, G1_gd, G1_sgd512, G1_sgd128, G1_sgd32, G1_sgd01, G1_gdwd]\n",
    "titles = ['Gram W1 at init.', 'GD', 'SGD-512', 'SGD-128', 'SGD-32', 'SGD-01', 'GD+wd (Gold)']\n",
    "\n",
    "def minmax(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "gs1 = [minmax(g ** 0.95) for g in gs1]\n",
    "vmin = min([g.min() for g in gs1])\n",
    "vmax = max([g.max() for g in gs1])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(titles), figsize=(16, len(gs1)))\n",
    "for i, g in enumerate(gs1):\n",
    "    im = axs[i].imshow(g, cmap='magma', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_title(f\"{titles[i]}\")\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irelnorms lines :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_median_and_percentiles(data, label, color):\n",
    "    data = np.array(data)\n",
    "    median = np.median(data, axis=0)\n",
    "    percentile_10 = np.percentile(data, 10, axis=0)\n",
    "    percentile_90 = np.percentile(data, 90, axis=0)\n",
    "    plt.plot(median, label=label, color=color)\n",
    "    plt.fill_between(range(len(median)), percentile_10, percentile_90, color=color, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irelnorms_gd = model_gd.irelnorms\n",
    "irelnorms_sgd512 = [model_sgd512[t].irelnorms for t in range(n_trajs)]\n",
    "irelnorms_sgd128 = [model_sgd128[t].irelnorms for t in range(n_trajs)]\n",
    "irelnorms_sgd32 = [model_sgd32[t].irelnorms for t in range(n_trajs)]\n",
    "irelnorms_sgd01 = [model_sgd01[t].irelnorms for t in range(n_trajs)]\n",
    "irelnorms_gdwd = model_gdwd.irelnorms\n",
    "\n",
    "# pad irelnorms_gdwd with 0s to match irelnorms_sgd512 len\n",
    "irelnorms_gdwd = irelnorms_gdwd + [0] * (len(irelnorms_sgd512[0]) - len(irelnorms_gdwd))\n",
    "irelnorms_gd = irelnorms_gd + [irelnorms_gd[-1]] * (len(irelnorms_sgd512[0]) - len(irelnorms_gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(irelnorms_gd, label='gd', color='red') # blue\n",
    "plot_median_and_percentiles(irelnorms_sgd512, 'sgd-512', 'orange')\n",
    "plot_median_and_percentiles(irelnorms_sgd128, 'sgd-128', 'blue')\n",
    "plot_median_and_percentiles(irelnorms_sgd32, 'sgd-32', 'green')\n",
    "plot_median_and_percentiles(irelnorms_sgd01, 'sgd-01', 'purple')\n",
    "plt.plot(irelnorms_gdwd, label='gd+wd', color='brown') # brown\n",
    "plt.title('irrelevant feature/weights norms over iters.')\n",
    "plt.grid(True, linestyle='-', linewidth=0.2, color='gray')\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gram matrices of second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_init = model_gd.W2_init\n",
    "W2_gd = model_gd.W2_post\n",
    "W2_sgd512 = model_sgd512[0].W2_post\n",
    "W2_sgd128 = model_sgd128[0].W2_post\n",
    "W2_sgd32 = model_sgd32[0].W2_post\n",
    "W2_sgd01 = model_sgd01[0].W2_post\n",
    "W2_gdwd = model_gdwd.W2_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2_init = abs(W2_init.T @ W2_init)\n",
    "G2_gd = abs(W2_gd.T @ W2_gd)\n",
    "G2_sgd512 = abs(W2_sgd512.T @ W2_sgd512)\n",
    "G2_sgd128 = abs(W2_sgd128.T @ W2_sgd128)\n",
    "G2_sgd32 = abs(W2_sgd32.T @ W2_sgd32)\n",
    "G2_sgd01 = abs(W2_sgd01.T @ W2_sgd01)\n",
    "G2_gdwd = abs(W2_gdwd.T @ W2_gdwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = [G2_init, G2_gd, G2_sgd512, G2_sgd128, G2_sgd32, G2_sgd01, G2_gdwd]\n",
    "titles = ['Gram W2 at init.', 'GD', 'SGD-512', 'SGD-128', 'SGD-32', 'SGD-01', 'GD+wd (Gold)']\n",
    "\n",
    "def minmax(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "gs2 = [minmax(g ** 0.95) for g in gs2]\n",
    "vmin = min([g.min() for g in gs2])\n",
    "vmax = max([g.max() for g in gs2])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(titles), figsize=(16, len(gs2)))\n",
    "for i, g in enumerate(gs2):\n",
    "    im = axs[i].imshow(g, cmap='magma', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_title(f\"{titles[i]}\")\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gram matrices of third layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3_init = model_gd.W3_init\n",
    "W3_gd = model_gd.W3_post\n",
    "W3_sgd512 = model_sgd512[0].W3_post\n",
    "W3_sgd128 = model_sgd128[0].W3_post\n",
    "W3_sgd32 = model_sgd32[0].W3_post\n",
    "W3_sgd01 = model_sgd01[0].W3_post\n",
    "W3_gdwd = model_gdwd.W3_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3_init = abs(W3_init.T @ W3_init)\n",
    "G3_gd = abs(W3_gd.T @ W3_gd)\n",
    "G3_sgd512 = abs(W3_sgd512.T @ W3_sgd512)\n",
    "G3_sgd128 = abs(W3_sgd128.T @ W3_sgd128)\n",
    "G3_sgd32 = abs(W3_sgd32.T @ W3_sgd32)\n",
    "G3_sgd01 = abs(W3_sgd01.T @ W3_sgd01)\n",
    "G3_gdwd = abs(W3_gdwd.T @ W3_gdwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3 = [G3_init, G3_gd, G3_sgd512, G3_sgd128, G3_sgd32, G3_sgd01, G3_gdwd]\n",
    "titles = ['Gram W2 at init.', 'GD', 'SGD-512', 'SGD-128', 'SGD-32', 'SGD-01', 'GD+wd (Gold)']\n",
    "\n",
    "def minmax(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "gs3 = [minmax(g ** 0.95) for g in gs3]\n",
    "vmin = min([g.min() for g in gs3])\n",
    "vmax = max([g.max() for g in gs3])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(titles), figsize=(16, len(gs3)))\n",
    "for i, g in enumerate(gs3):\n",
    "    im = axs[i].imshow(g, cmap='magma', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_title(f\"{titles[i]}\")\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesiscode-yovy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
